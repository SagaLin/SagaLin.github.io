<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Saga&#39;s bolg</title>
  <subtitle>JAVA</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://sagalin.github.io/blog/"/>
  <updated>2016-12-01T14:32:05.649Z</updated>
  <id>https://sagalin.github.io/blog/</id>
  
  <author>
    <name>Saga Lin</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>window下idea远程调试Hadoop环境部署</title>
    <link href="https://sagalin.github.io/blog/2016/11/27/window%E4%B8%8Bidea%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95Hadoop%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/"/>
    <id>https://sagalin.github.io/blog/2016/11/27/window下idea远程调试Hadoop环境部署/</id>
    <published>2016-11-27T15:25:03.000Z</published>
    <updated>2016-12-01T14:32:05.649Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/image/hadoop-image-logo.jpg" alt="img"></p>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><pre><code>在Linux上部署Hadoop环境后，要写相关开发程序的时候，却不知如何在window上idea开发后部署到Linux上运行。而且idea不像eclipse
</code></pre><p>上有辅助的开发插件，故在网上找了一些资料，其中有很多坑，在此记录下。</p>
<h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><h3 id="开发环境"><a href="#开发环境" class="headerlink" title="开发环境"></a>开发环境</h3><blockquote><p>Hadoop版本：2.5.2<br>idea版本：2016.2<br>Windows：win7</p>
</blockquote>
<h3 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h3><pre><code>hadoop ：http://hadoop.apache.org/releases.html
hadoop-common-2.2.0-bin ：https://github.com/srccodes/hadoop-common-2.2.0-bin
</code></pre><h3 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h3><p>   1.将hadoop-2.5.2.tar.gz解压到本地磁盘中，然后配置以下环境变量<br> <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">HADOOP_HOME=D:\hadoop\hadoop-2.5.2</div><div class="line"></div><div class="line">HADOOP_BIN_PATH=%HADOOP_HOME%\bin</div><div class="line"></div><div class="line">HADOOP_PREFIX=D:\hadoop\hadoop-2.5.2</div></pre></td></tr></table></figure></p>
<p>  2.将hadoop-common-2.2.0-bin下面所有的文件复制拷贝到HADOOP_HOME下的bin目录下覆盖<br>  3.将hadoop-common-2.2.0-bin下面的hadoo.dll拷贝覆盖到系统盘下的window/Window32/路径下</p>
<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><h3 id="项目配置"><a href="#项目配置" class="headerlink" title="项目配置"></a>项目配置</h3><pre><code>新建一个new maven project，pom.xml下面导入以下依赖：
</code></pre> <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line">&lt;dependencies&gt;</div><div class="line">        &lt;dependency&gt;</div><div class="line">            &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;</div><div class="line">            &lt;artifactId&gt;hadoop-common&lt;/artifactId&gt;</div><div class="line">            &lt;version&gt;2.5.2&lt;/version&gt;</div><div class="line">        &lt;/dependency&gt;</div><div class="line">        &lt;dependency&gt;</div><div class="line">            &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;</div><div class="line">            &lt;artifactId&gt;hadoop-mapreduce-client-core&lt;/artifactId&gt;</div><div class="line">            &lt;version&gt;2.5.2&lt;/version&gt;</div><div class="line">        &lt;/dependency&gt;</div><div class="line">        &lt;dependency&gt;</div><div class="line">            &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;</div><div class="line">            &lt;artifactId&gt;hadoop-mapreduce-client-jobclient&lt;/artifactId&gt;</div><div class="line">            &lt;version&gt;2.5.2&lt;/version&gt;</div><div class="line">        &lt;/dependency&gt;</div><div class="line">        &lt;dependency&gt;</div><div class="line">            &lt;groupId&gt;commons-cli&lt;/groupId&gt;</div><div class="line">            &lt;artifactId&gt;commons-cli&lt;/artifactId&gt;</div><div class="line">            &lt;version&gt;1.2&lt;/version&gt;</div><div class="line">        &lt;/dependency&gt;</div><div class="line">        &lt;dependency&gt;</div><div class="line">            &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;</div><div class="line">            &lt;artifactId&gt;hadoop-hdfs&lt;/artifactId&gt;</div><div class="line">            &lt;version&gt;2.5.2&lt;/version&gt;</div><div class="line">        &lt;/dependency&gt;</div><div class="line">    &lt;/dependencies&gt;</div><div class="line"> </div></pre></td></tr></table></figure>
<pre><code>下载依赖后打开 File&gt;&gt;Project structue,打开Libraries下面导入HADOOP_HOME下面的share/hadoop文件夹下的所有依赖。
</code></pre><p> <img src="/image/hadoop-idea-1.png" alt="img"></p>
<h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><pre><code>新建一个java类，代码如下：
</code></pre> <figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"><span class="keyword">import</span> java.util.StringTokenizer;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCount</span> </span>&#123;</div><div class="line"></div><div class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">TokenizerMapper</span></span></div><div class="line">            <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">Object</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt;&#123;</div><div class="line"></div><div class="line">        <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> IntWritable one = <span class="keyword">new</span> IntWritable(<span class="number">1</span>);</div><div class="line">        <span class="keyword">private</span> Text word = <span class="keyword">new</span> Text();</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Object key, Text value, Context context</span></span></div><div class="line">        ) <span class="keyword">throws</span> IOException, InterruptedException &#123;</div><div class="line">            StringTokenizer itr = <span class="keyword">new</span> StringTokenizer(value.toString());</div><div class="line">            <span class="keyword">while</span> (itr.hasMoreTokens()) &#123;</div><div class="line">                word.set(itr.nextToken());</div><div class="line">                context.write(word, one);</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">IntSumReducer</span></span></div><div class="line">            <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>,<span class="title">IntWritable</span>,<span class="title">Text</span>,<span class="title">IntWritable</span>&gt; &#123;</div><div class="line">        <span class="keyword">private</span> IntWritable result = <span class="keyword">new</span> IntWritable();</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values,</span></span></div><div class="line">                           Context context</div><div class="line">        ) <span class="keyword">throws</span> IOException, InterruptedException &#123;</div><div class="line">            <span class="keyword">int</span> sum = <span class="number">0</span>;</div><div class="line">            <span class="keyword">for</span> (IntWritable val : values) &#123;</div><div class="line">                sum += val.get();</div><div class="line">            &#125;</div><div class="line">            result.set(sum);</div><div class="line">            context.write(key, result);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">        <span class="comment">//System.setProperty("hadoop.home.dir", "E:\\program\\hadoop-2.5.2\\hadoop-2.5.2");</span></div><div class="line">        <span class="comment">//设置访问HDFS的用户名</span></div><div class="line">        System.setProperty(<span class="string">"HADOOP_USER_NAME"</span>, <span class="string">"root"</span>);</div><div class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</div><div class="line">        <span class="comment">//设置hdfs和yarn地址</span></div><div class="line">        conf.set(<span class="string">"fs.defaultFS"</span>, <span class="string">"hdfs://192.168.112.129:9000"</span>);</div><div class="line">        <span class="comment">//conf.set("yarn.resourcemanager.hostname","192.168.112.129");</span></div><div class="line">        Job job = Job.getInstance(conf, <span class="string">"word count"</span>);</div><div class="line">        job.setJarByClass(WordCount.class);</div><div class="line">        job.setMapperClass(TokenizerMapper.class);</div><div class="line">        job.setCombinerClass(IntSumReducer.class);</div><div class="line">        job.setReducerClass(IntSumReducer.class);</div><div class="line">        job.setOutputKeyClass(Text.class);</div><div class="line">        job.setOutputValueClass(IntWritable.class);</div><div class="line">        FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(args[<span class="number">0</span>]));</div><div class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(args[<span class="number">1</span>]));</div><div class="line">        System.exit(job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);</div><div class="line"></div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"> </div></pre></td></tr></table></figure>
<pre><code>在resources下面新建一个文件，文件名为log4j.properties,里面内容如下：
</code></pre> <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">log</span>4j.appender.console=org.apache.log4j.ConsoleAppender</div><div class="line"><span class="built_in">log</span>4j.appender.console.Target=System.out</div><div class="line"><span class="built_in">log</span>4j.appender.console.layout=org.apache.log4j.PatternLayout</div><div class="line"><span class="built_in">log</span>4j.appender.console.layout.ConversionPattern=%d&#123;ABSOLUTE&#125; %5p %c&#123;1&#125;:%L - %m%n</div><div class="line"><span class="built_in">log</span>4j.rootLogger=INFO, console</div></pre></td></tr></table></figure>
<h3 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h3><pre><code>在Linux的hdfs上放入自定义的txt文件
</code></pre> <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#建立输入目录</span></div><div class="line">hadoop fs -mkdir /input</div><div class="line"><span class="comment">#导入TXT文件</span></div><div class="line">hadoop fs -put /input/ ibmstockquotes.txt</div></pre></td></tr></table></figure>
<pre><code>在idea的下面配置 Run &gt;&gt; Edit configurations下面，配置program arguments,如下的输入文档和输出文件夹：
</code></pre> <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">/input/ibmstockquotes.txt</div><div class="line">/output/</div></pre></td></tr></table></figure>
<p> <img src="/image/hadoop-idea-2.png" alt="img"></p>
<pre><code>配置好后，记得将代码中IP修改为你Hadoop环境下的IP地址。
运行WordCount下面的main函数，在控制台中输出以下信息：
</code></pre> <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div></pre></td><td class="code"><pre><div class="line">21:29:25,488  INFO Job:1380 - Counters: 38</div><div class="line">	File System Counters</div><div class="line">		FILE: Number of bytes <span class="built_in">read</span>=1910374</div><div class="line">		FILE: Number of bytes written=3337228</div><div class="line">		FILE: Number of <span class="built_in">read</span> operations=0</div><div class="line">		FILE: Number of large <span class="built_in">read</span> operations=0</div><div class="line">		FILE: Number of write operations=0</div><div class="line">		HDFS: Number of bytes <span class="built_in">read</span>=1744108</div><div class="line">		HDFS: Number of bytes written=899694</div><div class="line">		HDFS: Number of <span class="built_in">read</span> operations=13</div><div class="line">		HDFS: Number of large <span class="built_in">read</span> operations=0</div><div class="line">		HDFS: Number of write operations=4</div><div class="line">	Map-Reduce Framework</div><div class="line">		Map input records=13819</div><div class="line">		Map output records=13820</div><div class="line">		Map output bytes=927334</div><div class="line">		Map output materialized bytes=954980</div><div class="line">		Input split bytes=122</div><div class="line">		Combine input records=13820</div><div class="line">		Combine output records=13820</div><div class="line">		Reduce input groups=13820</div><div class="line">		Reduce shuffle bytes=954980</div><div class="line">		Reduce input records=13820</div><div class="line">		Reduce output records=13820</div><div class="line">		Spilled Records=27640</div><div class="line">		Shuffled Maps =1</div><div class="line">		Failed Shuffles=0</div><div class="line">		Merged Map outputs=1</div><div class="line">		GC time elapsed (ms)=0</div><div class="line">		CPU time spent (ms)=0</div><div class="line">		Physical memory (bytes) snapshot=0</div><div class="line">		Virtual memory (bytes) snapshot=0</div><div class="line">		Total committed heap usage (bytes)=412090368</div><div class="line">	Shuffle Errors</div><div class="line">		BAD_ID=0</div><div class="line">		CONNECTION=0</div><div class="line">		IO_ERROR=0</div><div class="line">		WRONG_LENGTH=0</div><div class="line">		WRONG_MAP=0</div><div class="line">		WRONG_REDUCE=0</div><div class="line">	File Input Format Counters</div><div class="line">		Bytes Read=872054</div><div class="line">	File Output Format Counters</div><div class="line">		Bytes Written=899694</div></pre></td></tr></table></figure>
<pre><code>完成以上步骤就可以在idea上开发和运行Hadoop程序了。
</code></pre><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><h3 id="java-io-IOException-Could-not-locate-executable-null-bin-winutils-exe-in-the-Hadoop-binaries"><a href="#java-io-IOException-Could-not-locate-executable-null-bin-winutils-exe-in-the-Hadoop-binaries" class="headerlink" title="java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries."></a>java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.</h3><p> 这个问题是程序没有找到HADOOP_HOME文件目录，可以在main函数中加入下面代码解决：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">System.setProperty(<span class="string">"hadoop.home.dir"</span>, <span class="string">"E:\\program\\hadoop-2.5.2\\hadoop-2.5.2"</span>);</div></pre></td></tr></table></figure></p>
<h3 id="Connection-refused-no-further-information"><a href="#Connection-refused-no-further-information" class="headerlink" title="Connection refused: no further information"></a>Connection refused: no further information</h3><p> 这个问题是你Linux上hadoop配置问题，把core-site.xml,salves,hdfs-site.xml下面的localhost修改为程序中链接的IP地址。<br>修改完后，重启既可解决该问题。</p>
<h3 id="org-apache-hadoop-io-nativeio-NativeIO-Windows-access0-Ljava-lang-String-I-Z"><a href="#org-apache-hadoop-io-nativeio-NativeIO-Windows-access0-Ljava-lang-String-I-Z" class="headerlink" title="org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z"></a>org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z</h3><p> C:\Windows\System32下缺少hadoop.dll,把这个文件拷贝到C:\Windows\System32下面即可。<br> 注意：该文件在hadoop-common-2.2.0-bin下载的文件夹目录下。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>  以上便是Windows下idea远程调试Hadoop和开发环境的配置。本人在配置上也遇到很多问题。都是弄和挺久才把环境配置好的，其中<br>多多少少都有些收获。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/image/hadoop-image-logo.jpg&quot; alt=&quot;img&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;在Lin
    
    </summary>
    
    
      <category term="idea" scheme="https://sagalin.github.io/blog/tags/idea/"/>
    
      <category term="hadoop" scheme="https://sagalin.github.io/blog/tags/hadoop/"/>
    
  </entry>
  
  <entry>
    <title>hexo windows下环境搭建</title>
    <link href="https://sagalin.github.io/blog/2016/11/26/hexo%20windows%E4%B8%8B%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    <id>https://sagalin.github.io/blog/2016/11/26/hexo windows下环境搭建/</id>
    <published>2016-11-26T06:49:41.000Z</published>
    <updated>2016-11-26T07:41:44.659Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>  Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。</p>
<h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><p>  主要本文主要是针对 window平台和 Hexo 3.x版本</p>
<h3 id="安装GitHub-Windows"><a href="#安装GitHub-Windows" class="headerlink" title="安装GitHub Windows"></a>安装GitHub Windows</h3><p>GitHub Windows<br>  傻瓜式的安装，按照操作提示即可，最好翻墙下载。</p>
<h3 id="安装Node-JS"><a href="#安装Node-JS" class="headerlink" title="安装Node.JS"></a>安装Node.JS</h3><p>  NodeJs<br>  注意 安装完成后添加Path环境变量，使npm命令生效。新版已经会自动配置Path</p>
<h3 id="安装Hexo"><a href="#安装Hexo" class="headerlink" title="安装Hexo"></a>安装Hexo</h3><p>  1.安装好Github后，配置好Github home 目录(在setting&gt;&gt;option上配置)<br>  2.打开git sell，输入以下命令进行安装<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">pm install hexo-cli -g</div><div class="line">npm install hexo --save</div><div class="line"></div><div class="line"><span class="comment">#如果命令无法运行，可以尝试更换taobao的npm源</span></div><div class="line">npm install -g cnpm --registry=https://registry.npm.taobao.org</div></pre></td></tr></table></figure></p>
<h2 id="Hexo初始化配置"><a href="#Hexo初始化配置" class="headerlink" title="Hexo初始化配置"></a>Hexo初始化配置</h2><h3 id="创建Hexo-project"><a href="#创建Hexo-project" class="headerlink" title="创建Hexo project"></a>创建Hexo project</h3><p>  安装完Hexo后，将git shell 切换到自己的工作目录下面<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#创建项目文件件</span></div><div class="line">$ mkdir &lt;folder&gt;</div><div class="line"><span class="comment">#进入项目文件夹中，并生成Hexo项目</span></div><div class="line">$ hexo init &lt;folder&gt;</div><div class="line"><span class="variable">$cd</span> &lt;folder&gt;</div><div class="line"><span class="variable">$npm</span> install</div></pre></td></tr></table></figure></p>
<h3 id="安装Hexo-插件"><a href="#安装Hexo-插件" class="headerlink" title="安装Hexo 插件"></a>安装Hexo 插件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">npm install hexo-generator-index --save</div><div class="line">npm install hexo-generator-archive --save</div><div class="line">npm install hexo-generator-category --save</div><div class="line">npm install hexo-generator-tag --save</div><div class="line">npm install hexo-server --save</div><div class="line">npm install hexo-deployer-git --save</div><div class="line">npm install hexo-deployer-heroku --save</div><div class="line">npm install hexo-deployer-rsync --save</div><div class="line">npm install hexo-deployer-openshift --save</div><div class="line">npm install hexo-renderer-marked@0.2 --save</div><div class="line">npm install hexo-renderer-stylus@0.2 --save</div><div class="line">npm install hexo-generator-feed@1 --save</div><div class="line">npm install hexo-generator-sitemap@1 --save</div></pre></td></tr></table></figure>
<h3 id="查看效果"><a href="#查看效果" class="headerlink" title="查看效果"></a>查看效果</h3><p>  继续执行以下命令，成功后可登录localhost:4000查看效果<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hexo server</div></pre></td></tr></table></figure></p>
<p>  如果端口被占用，可以使用其他端口</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hexo server -p 5000</div></pre></td></tr></table></figure>
<p>  调用以下命令可以查看hexo help<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hexo h</div></pre></td></tr></table></figure></p>
<h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><pre><code>https://wsgzao.github.io/post/hexo-guide/
https://hexo.io/zh-cn/docs/index.html
</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;  Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成
    
    </summary>
    
    
      <category term="hexo" scheme="https://sagalin.github.io/blog/tags/hexo/"/>
    
  </entry>
  
</feed>
